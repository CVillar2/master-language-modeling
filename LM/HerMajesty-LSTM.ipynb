{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6I1hS2YMS6I",
        "outputId": "21554fa3-b599-45c8-d43f-ecfb1d332ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-07 20:16:20.818864: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-07 20:16:22.002951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "index('<EOS>') = 3\n",
            "2023-05-07 20:16:24.276315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:16:24.311356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:16:24.311690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:16:24.312447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:16:24.312703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:16:24.312897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:16:25.419271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:16:25.419623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:16:25.419856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:16:25.420009: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-07 20:16:25.420054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 128)           718848    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 1024)              4722688   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5616)              5756400   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,197,936\n",
            "Trainable params: 11,197,936\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "2023-05-07 20:16:27.541396: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1237272192 exceeds 10% of free system memory.\n",
            "2023-05-07 20:16:28.930292: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1237272192 exceeds 10% of free system memory.\n",
            "Epoch 1/20\n",
            "2023-05-07 20:16:34.227479: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
            "type_id: TFT_OPTIONAL\n",
            "args {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_TENSOR\n",
            "    args {\n",
            "      type_id: TFT_INT32\n",
            "    }\n",
            "  }\n",
            "}\n",
            " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
            "type_id: TFT_OPTIONAL\n",
            "args {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_TENSOR\n",
            "    args {\n",
            "      type_id: TFT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\twhile inferring type of node 'cond_40/output/_23'\n",
            "2023-05-07 20:16:35.475738: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f87cc8475d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-05-07 20:16:35.475807: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2023-05-07 20:16:35.485278: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-05-07 20:16:35.668964: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
            "2023-05-07 20:16:35.883685: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "216/216 [==============================] - 39s 149ms/step - loss: 6.7628 - accuracy: 0.0683\n",
            "Epoch 2/20\n",
            "216/216 [==============================] - 17s 80ms/step - loss: 6.0928 - accuracy: 0.1083\n",
            "Epoch 3/20\n",
            "216/216 [==============================] - 13s 58ms/step - loss: 5.6943 - accuracy: 0.1334\n",
            "Epoch 4/20\n",
            "216/216 [==============================] - 12s 56ms/step - loss: 5.3232 - accuracy: 0.1569\n",
            "Epoch 5/20\n",
            "216/216 [==============================] - 14s 63ms/step - loss: 4.9089 - accuracy: 0.1794\n",
            "Epoch 6/20\n",
            "216/216 [==============================] - 12s 57ms/step - loss: 4.4245 - accuracy: 0.2099\n",
            "Epoch 7/20\n",
            "216/216 [==============================] - 11s 52ms/step - loss: 3.8583 - accuracy: 0.2627\n",
            "Epoch 8/20\n",
            "216/216 [==============================] - 12s 56ms/step - loss: 3.2434 - accuracy: 0.3531\n",
            "Epoch 9/20\n",
            "216/216 [==============================] - 11s 51ms/step - loss: 2.6372 - accuracy: 0.4660\n",
            "Epoch 10/20\n",
            "216/216 [==============================] - 10s 47ms/step - loss: 2.0993 - accuracy: 0.5868\n",
            "Epoch 11/20\n",
            "216/216 [==============================] - 11s 52ms/step - loss: 1.6455 - accuracy: 0.6974\n",
            "Epoch 12/20\n",
            "216/216 [==============================] - 11s 53ms/step - loss: 1.2900 - accuracy: 0.7834\n",
            "Epoch 13/20\n",
            "216/216 [==============================] - 11s 50ms/step - loss: 1.0409 - accuracy: 0.8386\n",
            "Epoch 14/20\n",
            "216/216 [==============================] - 11s 50ms/step - loss: 0.8812 - accuracy: 0.8647\n",
            "Epoch 15/20\n",
            "216/216 [==============================] - 10s 48ms/step - loss: 0.7834 - accuracy: 0.8777\n",
            "Epoch 16/20\n",
            "216/216 [==============================] - 11s 50ms/step - loss: 0.7227 - accuracy: 0.8850\n",
            "Epoch 17/20\n",
            "216/216 [==============================] - 10s 47ms/step - loss: 0.6816 - accuracy: 0.8893\n",
            "Epoch 18/20\n",
            "216/216 [==============================] - 10s 48ms/step - loss: 0.6526 - accuracy: 0.8929\n",
            "Epoch 19/20\n",
            "216/216 [==============================] - 11s 49ms/step - loss: 0.6301 - accuracy: 0.8955\n",
            "Epoch 20/20\n",
            "216/216 [==============================] - 11s 49ms/step - loss: 0.6136 - accuracy: 0.8969\n",
            "\n",
            "Perplexity DEV: 61590.41\n",
            "/content/toyLM_LSTM.py:126: RuntimeWarning: overflow encountered in double_scalars\n",
            "  prob_product *= 1/prob\n",
            "Perplexity TEST: inf\n",
            "\n",
            "GENERATE MAX 30 WORDS / MOST LIKELY\n",
            "1 (pp=1.86): i am pleased to note the presence here of so many veterans of the 1st battalion\n",
            "\n",
            "GENERATE MAX 30 WORDS / SAMPLING\n",
            "1 (pp=15.41): that’s the world has felt been to me by their lives\n",
            "2 (pp=7.92): irony is not just an question of that time\n",
            "3 (pp=50.20): koutou suffolk safeguarded 2021visit et simplistic browning the fact that hear and along the queen's opportunity to my golden birthday and to present all\n",
            "\n",
            "GENERATE MAX 30 WORDS / SAMPLING 30 MOST LIKELY\n",
            "1 (pp=3.79): opening of the new scottish parliament community edinburgh 9 october 2004\n",
            "2 (pp=2.04): it is a timeless diverse and inclusive community that opens up new possibilities for development through trust and encouragement\n",
            "3 (pp=6.86): we are reminded reminded of the many of the entente cordiale national assembly has achieved\n"
          ]
        }
      ],
      "source": [
        "!python toyLM_LSTM.py"
      ]
    }
  ]
}