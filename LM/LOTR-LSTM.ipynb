{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6I1hS2YMS6I",
        "outputId": "88cde73f-98fd-43f2-a5a2-15b626b04491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-07 20:25:43.386090: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-07 20:25:44.412684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "index('<EOS>') = 3\n",
            "2023-05-07 20:25:46.446933: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:25:46.483473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:25:46.483899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:25:46.484778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:25:46.485072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:25:46.485325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:25:47.506754: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:25:47.507120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:25:47.507400: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 20:25:47.507617: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-07 20:25:47.507669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 128)           936960    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 1024)              4722688   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 7320)              7503000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,162,648\n",
            "Trainable params: 13,162,648\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "2023-05-07 20:25:49.401868: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1745644320 exceeds 10% of free system memory.\n",
            "2023-05-07 20:25:51.280536: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1745644320 exceeds 10% of free system memory.\n",
            "Epoch 1/20\n",
            "2023-05-07 20:25:56.250268: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
            "type_id: TFT_OPTIONAL\n",
            "args {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_TENSOR\n",
            "    args {\n",
            "      type_id: TFT_INT32\n",
            "    }\n",
            "  }\n",
            "}\n",
            " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
            "type_id: TFT_OPTIONAL\n",
            "args {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_TENSOR\n",
            "    args {\n",
            "      type_id: TFT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\twhile inferring type of node 'cond_40/output/_23'\n",
            "2023-05-07 20:25:57.326633: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f15e5e2ffb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-05-07 20:25:57.326689: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2023-05-07 20:25:57.339414: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-05-07 20:25:57.501356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
            "2023-05-07 20:25:57.697041: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "233/233 [==============================] - 36s 131ms/step - loss: 6.8900 - accuracy: 0.0594\n",
            "Epoch 2/20\n",
            "233/233 [==============================] - 15s 64ms/step - loss: 6.2894 - accuracy: 0.0866\n",
            "Epoch 3/20\n",
            "233/233 [==============================] - 15s 63ms/step - loss: 5.9446 - accuracy: 0.1068\n",
            "Epoch 4/20\n",
            "233/233 [==============================] - 13s 55ms/step - loss: 5.6323 - accuracy: 0.1216\n",
            "Epoch 5/20\n",
            "233/233 [==============================] - 13s 55ms/step - loss: 5.3142 - accuracy: 0.1331\n",
            "Epoch 6/20\n",
            "233/233 [==============================] - 12s 50ms/step - loss: 4.9606 - accuracy: 0.1470\n",
            "Epoch 7/20\n",
            "233/233 [==============================] - 12s 52ms/step - loss: 4.5512 - accuracy: 0.1680\n",
            "Epoch 8/20\n",
            "233/233 [==============================] - 12s 51ms/step - loss: 4.0766 - accuracy: 0.2141\n",
            "Epoch 9/20\n",
            "233/233 [==============================] - 12s 50ms/step - loss: 3.5549 - accuracy: 0.2944\n",
            "Epoch 10/20\n",
            "233/233 [==============================] - 12s 51ms/step - loss: 3.0442 - accuracy: 0.3888\n",
            "Epoch 11/20\n",
            "233/233 [==============================] - 11s 49ms/step - loss: 2.5671 - accuracy: 0.4924\n",
            "Epoch 12/20\n",
            "233/233 [==============================] - 12s 51ms/step - loss: 2.1391 - accuracy: 0.5951\n",
            "Epoch 13/20\n",
            "233/233 [==============================] - 12s 52ms/step - loss: 1.7755 - accuracy: 0.6838\n",
            "Epoch 14/20\n",
            "233/233 [==============================] - 12s 51ms/step - loss: 1.4825 - accuracy: 0.7519\n",
            "Epoch 15/20\n",
            "233/233 [==============================] - 12s 51ms/step - loss: 1.2640 - accuracy: 0.7967\n",
            "Epoch 16/20\n",
            "233/233 [==============================] - 12s 53ms/step - loss: 1.1057 - accuracy: 0.8252\n",
            "Epoch 17/20\n",
            "233/233 [==============================] - 12s 50ms/step - loss: 0.9948 - accuracy: 0.8412\n",
            "Epoch 18/20\n",
            "233/233 [==============================] - 12s 50ms/step - loss: 0.9171 - accuracy: 0.8531\n",
            "Epoch 19/20\n",
            "233/233 [==============================] - 12s 51ms/step - loss: 0.8597 - accuracy: 0.8623\n",
            "Epoch 20/20\n",
            "233/233 [==============================] - 12s 51ms/step - loss: 0.8149 - accuracy: 0.8684\n",
            "\n",
            "/content/toyLM_LSTM.py:126: RuntimeWarning: overflow encountered in double_scalars\n",
            "  prob_product *= 1/prob\n",
            "Perplexity DEV: inf\n",
            "Perplexity TEST: inf\n",
            "\n",
            "GENERATE MAX 30 WORDS / MOST LIKELY\n",
            "1 (pp=2.90): he had been just a long long time and wasforgetting this sort of thing\n",
            "\n",
            "GENERATE MAX 30 WORDS / SAMPLING\n",
            "1 (pp=238.23): consultone slope ofdwalins disturbing eyebrows\n",
            "2 (pp=121.25): nosing tomorrow\n",
            "3 (pp=21.96): pasture andadventures sprouted one fili are thorin to their things think of the spiders took no said\n",
            "\n",
            "GENERATE MAX 30 WORDS / SAMPLING 30 MOST LIKELY\n",
            "1 (pp=13.05): curse it was in the light of this way he thought was fell along that nori something into different under their nose and he was feeling in the house looking\n",
            "2 (pp=10.84): they dont think of gandalf and that may have to have done his eyesgleaming in a sort of people\n",
            "3 (pp=71.01): o\n"
          ]
        }
      ],
      "source": [
        "!python toyLM_LSTM.py"
      ]
    }
  ]
}