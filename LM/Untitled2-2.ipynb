{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6I1hS2YMS6I",
        "outputId": "40377b6e-20b0-47b0-c673-76697ccffc67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-07 19:27:29.253370: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-07 19:27:30.282702: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "index('<EOS>') = 3\n",
            "2023-05-07 19:27:32.358376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 19:27:32.834527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 19:27:32.835004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 19:27:32.835813: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 19:27:32.836061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 19:27:32.836288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 19:27:35.509471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 19:27:35.509812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 19:27:35.510021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-07 19:27:35.510178: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-05-07 19:27:35.510221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 64)            359424    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 1024)              4460544   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5616)              5756400   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,576,368\n",
            "Trainable params: 10,576,368\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "2023-05-07 19:27:37.481584: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1237272192 exceeds 10% of free system memory.\n",
            "2023-05-07 19:27:38.838436: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1237272192 exceeds 10% of free system memory.\n",
            "Epoch 1/20\n",
            "2023-05-07 19:27:43.153300: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
            "type_id: TFT_OPTIONAL\n",
            "args {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_TENSOR\n",
            "    args {\n",
            "      type_id: TFT_INT32\n",
            "    }\n",
            "  }\n",
            "}\n",
            " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
            "type_id: TFT_OPTIONAL\n",
            "args {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_TENSOR\n",
            "    args {\n",
            "      type_id: TFT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\twhile inferring type of node 'cond_40/output/_23'\n",
            "2023-05-07 19:27:46.731178: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f07f892acc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-05-07 19:27:46.731231: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2023-05-07 19:27:46.859804: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-05-07 19:27:47.520001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
            "2023-05-07 19:27:48.038291: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "216/216 [==============================] - 38s 137ms/step - loss: 6.8182 - accuracy: 0.0610\n",
            "Epoch 2/20\n",
            "216/216 [==============================] - 14s 63ms/step - loss: 6.1912 - accuracy: 0.1016\n",
            "Epoch 3/20\n",
            "216/216 [==============================] - 13s 62ms/step - loss: 5.8396 - accuracy: 0.1196\n",
            "Epoch 4/20\n",
            "216/216 [==============================] - 11s 52ms/step - loss: 5.5255 - accuracy: 0.1389\n",
            "Epoch 5/20\n",
            "216/216 [==============================] - 10s 47ms/step - loss: 5.1695 - accuracy: 0.1600\n",
            "Epoch 6/20\n",
            "216/216 [==============================] - 11s 50ms/step - loss: 4.7512 - accuracy: 0.1813\n",
            "Epoch 7/20\n",
            "216/216 [==============================] - 10s 47ms/step - loss: 4.2542 - accuracy: 0.2122\n",
            "Epoch 8/20\n",
            "216/216 [==============================] - 10s 47ms/step - loss: 3.6937 - accuracy: 0.2783\n",
            "Epoch 9/20\n",
            "216/216 [==============================] - 10s 47ms/step - loss: 3.1072 - accuracy: 0.3721\n",
            "Epoch 10/20\n",
            "216/216 [==============================] - 10s 48ms/step - loss: 2.5499 - accuracy: 0.4825\n",
            "Epoch 11/20\n",
            "216/216 [==============================] - 11s 51ms/step - loss: 2.0550 - accuracy: 0.5983\n",
            "Epoch 12/20\n",
            "216/216 [==============================] - 10s 48ms/step - loss: 1.6362 - accuracy: 0.7013\n",
            "Epoch 13/20\n",
            "216/216 [==============================] - 11s 51ms/step - loss: 1.3090 - accuracy: 0.7815\n",
            "Epoch 14/20\n",
            "216/216 [==============================] - 10s 46ms/step - loss: 1.0711 - accuracy: 0.8316\n",
            "Epoch 15/20\n",
            "216/216 [==============================] - 10s 46ms/step - loss: 0.9176 - accuracy: 0.8577\n",
            "Epoch 16/20\n",
            "216/216 [==============================] - 11s 50ms/step - loss: 0.8216 - accuracy: 0.8705\n",
            "Epoch 17/20\n",
            "216/216 [==============================] - 10s 48ms/step - loss: 0.7622 - accuracy: 0.8774\n",
            "Epoch 18/20\n",
            "216/216 [==============================] - 10s 48ms/step - loss: 0.7210 - accuracy: 0.8819\n",
            "Epoch 19/20\n",
            "216/216 [==============================] - 11s 53ms/step - loss: 0.6905 - accuracy: 0.8857\n",
            "Epoch 20/20\n",
            "216/216 [==============================] - 11s 51ms/step - loss: 0.6664 - accuracy: 0.8884\n",
            "\n",
            "Perplexity DEV: 75568.31\n",
            "/content/toyLM_LSTM.py:126: RuntimeWarning: overflow encountered in double_scalars\n",
            "  prob_product *= 1/prob\n",
            "Perplexity TEST: inf\n",
            "\n",
            "GENERATE MAX 30 WORDS / MOST LIKELY\n",
            "1 (pp=2.26): i am pleased that prince harry is able to present a new colour to the royal air force regiment in this your 75th anniversary year on my behalf as your\n",
            "\n",
            "GENERATE MAX 30 WORDS / SAMPLING\n",
            "1 (pp=12.50): condolences provincial like to much this parliament and scotland's people who had over your warm fifty years as we go with the hand and warmth required which i saw the\n",
            "2 (pp=9.73): symbol span divides they unite\n",
            "3 (pp=13.95): like to home on a dialogue to ensure those who work to the deeper we share a deep record of the members of its national forces\n",
            "\n",
            "GENERATE MAX 30 WORDS / SAMPLING 30 MOST LIKELY\n",
            "1 (pp=13.67): i hope and to thank the opportunity to see your admiration to your proud of the emergency services\n",
            "2 (pp=1.95): president ladies and gentlemen for me there are constants enduring reference points in these tides of change and progress\n",
            "3 (pp=1.43): prime minister ladies and gentlemenwhen prince philip and i were married on this day fifty years ago britain had just endured six years of war emerging battered but victorious\n"
          ]
        }
      ],
      "source": [
        "!python toyLM_LSTM.py"
      ]
    }
  ]
}